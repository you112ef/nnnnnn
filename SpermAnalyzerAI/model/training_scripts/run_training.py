#!/usr/bin/env python3
# SpermAnalyzerAI - Complete Training Pipeline Runner
import sys
import argparse
from pathlib import Path
from loguru import logger
import time

# Ø¥Ø¶Ø§ÙØ© Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ù„Ù„Ù…Ø³Ø§Ø±
sys.path.append(str(Path(__file__).parent.parent))

from train_yolo import SpermYOLOTrainer
from data_preprocessing import SpermDataPreprocessor
from model_evaluation import SpermModelEvaluator
from model_deployment import SpermModelDeployer

class SpermTrainingPipeline:
    """Ø®Ø· ØªØ¯Ø±ÙŠØ¨ Ø´Ø§Ù…Ù„ Ù„Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­ÙŠÙˆØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†ÙˆÙŠØ©"""
    
    def __init__(self, config: dict):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø®Ø· Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        
        Args:
            config: Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        """
        self.config = config
        self.project_root = Path(__file__).parent.parent.parent
        
        # Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
        self.data_path = self.project_root / "data"
        self.models_path = self.project_root / "models"
        self.results_path = self.project_root / "results"
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
        self.data_path.mkdir(exist_ok=True)
        self.models_path.mkdir(exist_ok=True)
        self.results_path.mkdir(exist_ok=True)
        
        logger.info(f"Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹: {self.project_root}")
    
    def run_data_preprocessing(self) -> bool:
        """ØªØ´ØºÙŠÙ„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        logger.info("ğŸ”„ Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
        
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            preprocessor = SpermDataPreprocessor(
                input_path=str(self.data_path / "raw"),
                output_path=str(self.data_path / "processed")
            )
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            preprocessor.process_dataset(
                quality_threshold=self.config.get('quality_threshold', 0.3),
                augmentation_factor=self.config.get('augmentation_factor', 2),
                extract_video_frames=self.config.get('extract_video_frames', True)
            )
            
            logger.info("âœ… ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            return False
    
    def run_model_training(self) -> str:
        """ØªØ´ØºÙŠÙ„ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        logger.info("ğŸ¤– Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
        
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯Ø±Ø¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            trainer = SpermYOLOTrainer(
                data_path=str(self.data_path),
                model_size=self.config.get('model_size', 'nano')
            )
            
            # ØªØ­Ø¯ÙŠØ« Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
            if 'training_config' in self.config:
                trainer.training_config.update(self.config['training_config'])
            
            # Ø¥Ù†Ø´Ø§Ø¡ ØªÙƒÙˆÙŠÙ† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            data_config = trainer.create_dataset_config()
            
            # Ø¥Ù†ØªØ§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§ØµØ·Ù†Ø§Ø¹ÙŠØ© Ø¥Ø°Ø§ Ù„Ù… ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ©
            processed_images = list((self.data_path / "processed" / "images" / "train").glob("*.jpg"))
            if len(processed_images) == 0:
                logger.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ© - Ø¥Ù†ØªØ§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§ØµØ·Ù†Ø§Ø¹ÙŠØ©...")
                trainer.generate_synthetic_data(
                    count=self.config.get('synthetic_data_count', 1000)
                )
            
            # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            model_path, training_results = trainer.train_model(data_config)
            
            logger.info(f"âœ… ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ù†Ø¬Ø§Ø­: {model_path}")
            return model_path
            
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
            return ""
    
    def run_model_evaluation(self, model_path: str) -> dict:
        """ØªØ´ØºÙŠÙ„ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        logger.info("ğŸ“Š Ø¨Ø¯Ø¡ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
        
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‚ÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            evaluator = SpermModelEvaluator(
                model_path=model_path,
                test_data_path=str(self.data_path / "processed")
            )
            
            # ØªØ´ØºÙŠÙ„ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
            metrics = evaluator.run_evaluation()
            
            logger.info("âœ… ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¨Ù†Ø¬Ø§Ø­")
            return metrics
            
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
            return {}
    
    def run_model_deployment(self, model_path: str) -> bool:
        """ØªØ´ØºÙŠÙ„ Ù†Ø´Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        logger.info("ğŸš€ Ø¨Ø¯Ø¡ Ù†Ø´Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
        
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù†Ø´Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            deployer = SpermModelDeployer(
                model_path=model_path,
                output_dir=str(self.models_path / "deployed")
            )
            
            # Ù†Ø´Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            success = deployer.deploy_all_formats()
            
            if success:
                logger.info("âœ… ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ù†Ø´Ø± Ø¨Ù†Ø¬Ø§Ø­")
            else:
                logger.warning("âš ï¸ ØªÙ… Ø§Ù„Ù†Ø´Ø± Ù…Ø¹ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„")
            
            return success
            
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ù†Ø´Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
            return False
    
    def run_full_pipeline(self) -> dict:
        """ØªØ´ØºÙŠÙ„ Ø®Ø· Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙƒØ§Ù…Ù„"""
        logger.info("ğŸ¯ Ø¨Ø¯Ø¡ Ø®Ø· Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù€ Sperm Analyzer AI")
        
        start_time = time.time()
        results = {
            'start_time': start_time,
            'stages': {},
            'final_model_path': "",
            'evaluation_metrics': {},
            'deployment_success': False,
            'total_time': 0
        }
        
        # 1. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        stage_start = time.time()
        if self.config.get('run_preprocessing', True):
            preprocessing_success = self.run_data_preprocessing()
            results['stages']['preprocessing'] = {
                'success': preprocessing_success,
                'time': time.time() - stage_start
            }
            
            if not preprocessing_success and self.config.get('require_preprocessing', False):
                logger.error("ÙØ´Ù„ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª - ØªÙˆÙ‚Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨")
                return results
        
        # 2. ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        stage_start = time.time()
        model_path = self.run_model_training()
        results['stages']['training'] = {
            'success': bool(model_path),
            'time': time.time() - stage_start,
            'model_path': model_path
        }
        results['final_model_path'] = model_path
        
        if not model_path:
            logger.error("ÙØ´Ù„ ÙÙŠ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ - ØªÙˆÙ‚Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨")
            return results
        
        # 3. ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        if self.config.get('run_evaluation', True):
            stage_start = time.time()
            evaluation_metrics = self.run_model_evaluation(model_path)
            results['stages']['evaluation'] = {
                'success': bool(evaluation_metrics),
                'time': time.time() - stage_start
            }
            results['evaluation_metrics'] = evaluation_metrics
        
        # 4. Ù†Ø´Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        if self.config.get('run_deployment', True):
            stage_start = time.time()
            deployment_success = self.run_model_deployment(model_path)
            results['stages']['deployment'] = {
                'success': deployment_success,
                'time': time.time() - stage_start
            }
            results['deployment_success'] = deployment_success
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ
        results['total_time'] = time.time() - start_time
        
        # Ø·Ø¨Ø§Ø¹Ø© Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        self.print_pipeline_summary(results)
        
        return results
    
    def print_pipeline_summary(self, results: dict):
        """Ø·Ø¨Ø§Ø¹Ø© Ù…Ù„Ø®Øµ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
        print("\n" + "="*60)
        print("ğŸ¯ Ù…Ù„Ø®Øµ Ù†ØªØ§Ø¦Ø¬ ØªØ¯Ø±ÙŠØ¨ Sperm Analyzer AI")
        print("="*60)
        
        # Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø±Ø§Ø­Ù„
        for stage_name, stage_info in results['stages'].items():
            status = "âœ… Ù†Ø¬Ø­" if stage_info['success'] else "âŒ ÙØ´Ù„"
            time_str = f"{stage_info['time']:.2f}s"
            print(f"{stage_name.capitalize()}: {status} ({time_str})")
        
        print(f"\nØ§Ù„ÙˆÙ‚Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {results['total_time']:.2f} Ø«Ø§Ù†ÙŠØ©")
        
        # Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        if results['final_model_path']:
            print(f"Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: {results['final_model_path']}")
        
        # Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
        if results['evaluation_metrics']:
            metrics = results['evaluation_metrics']
            print(f"\nÙ…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡:")
            print(f"  Precision: {metrics.get('precision', 0):.4f}")
            print(f"  Recall: {metrics.get('recall', 0):.4f}")
            print(f"  F1-Score: {metrics.get('f1_score', 0):.4f}")
            print(f"  FPS: {metrics.get('fps', 0):.2f}")
        
        # Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø´Ø±
        if results['deployment_success']:
            print(f"\nğŸš€ ØªÙ… Ù†Ø´Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ: models/deployed/")
        
        print("="*60)

def create_default_config() -> dict:
    """Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ©"""
    return {
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¹Ø§Ù…Ø©
        'run_preprocessing': True,
        'run_evaluation': True,
        'run_deployment': True,
        'require_preprocessing': False,
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        'quality_threshold': 0.3,
        'augmentation_factor': 2,
        'extract_video_frames': True,
        'synthetic_data_count': 500,
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        'model_size': 'nano',  # nano, small, medium, large, xlarge
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        'training_config': {
            'epochs': 50,
            'batch_size': 16,
            'imgsz': 640,
            'lr0': 0.01,
            'patience': 10,
            'save_period': 5,
            'workers': 4,
            'device': 'auto'
        }
    }

def parse_arguments():
    """ØªØ­Ù„ÙŠÙ„ Ù…Ø¯Ø®Ù„Ø§Øª Ø³Ø·Ø± Ø§Ù„Ø£ÙˆØ§Ù…Ø±"""
    parser = argparse.ArgumentParser(
        description="SpermAnalyzerAI - Ø®Ø· ØªØ¯Ø±ÙŠØ¨ Ø´Ø§Ù…Ù„ Ù„Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­ÙŠÙˆØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†ÙˆÙŠØ©"
    )
    
    parser.add_argument(
        '--config', '-c',
        type=str,
        help="Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª JSON (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)"
    )
    
    parser.add_argument(
        '--model-size', '-m',
        choices=['nano', 'small', 'medium', 'large', 'xlarge'],
        default='nano',
        help="Ø­Ø¬Ù… Ù†Ù…ÙˆØ°Ø¬ YOLOv8 (Ø§ÙØªØ±Ø§Ø¶ÙŠ: nano)"
    )
    
    parser.add_argument(
        '--epochs', '-e',
        type=int,
        default=50,
        help="Ø¹Ø¯Ø¯ Ø¯ÙˆØ±Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Ø§ÙØªØ±Ø§Ø¶ÙŠ: 50)"
    )
    
    parser.add_argument(
        '--batch-size', '-b',
        type=int,
        default=16,
        help="Ø­Ø¬Ù… Ø§Ù„Ø¯ÙØ¹Ø© (Ø§ÙØªØ±Ø§Ø¶ÙŠ: 16)"
    )
    
    parser.add_argument(
        '--skip-preprocessing',
        action='store_true',
        help="ØªØ®Ø·ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"
    )
    
    parser.add_argument(
        '--skip-evaluation',
        action='store_true',
        help="ØªØ®Ø·ÙŠ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"
    )
    
    parser.add_argument(
        '--skip-deployment',
        action='store_true',
        help="ØªØ®Ø·ÙŠ Ù†Ø´Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"
    )
    
    parser.add_argument(
        '--synthetic-only',
        action='store_true',
        help="Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØ© ÙÙ‚Ø·"
    )
    
    return parser.parse_args()

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
    args = parse_arguments()
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    config = create_default_config()
    
    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
    config['model_size'] = args.model_size
    config['training_config']['epochs'] = args.epochs
    config['training_config']['batch_size'] = args.batch_size
    config['run_preprocessing'] = not args.skip_preprocessing
    config['run_evaluation'] = not args.skip_evaluation
    config['run_deployment'] = not args.skip_deployment
    
    if args.synthetic_only:
        config['synthetic_data_count'] = 1000
        config['run_preprocessing'] = False
    
    # ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¥Ø°Ø§ ØªÙ… ØªØ­Ø¯ÙŠØ¯Ù‡
    if args.config:
        import json
        with open(args.config, 'r', encoding='utf-8') as f:
            custom_config = json.load(f)
            config.update(custom_config)
    
    # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ´ØºÙŠÙ„ Ø®Ø· Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    pipeline = SpermTrainingPipeline(config)
    
    try:
        results = pipeline.run_full_pipeline()
        
        # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        results_file = pipeline.results_path / "training_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            import json
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"ØªÙ… Ø­ÙØ¸ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {results_file}")
        
        # ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø±ÙˆØ¬
        success = (
            results['final_model_path'] and
            results['stages'].get('training', {}).get('success', False)
        )
        
        sys.exit(0 if success else 1)
        
    except KeyboardInterrupt:
        logger.info("ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
        sys.exit(1)
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()